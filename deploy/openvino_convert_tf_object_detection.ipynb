{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert TensorFlow Object Detection API Models\n",
    "[Documentation](https://software.intel.com/en-us/articles/OpenVINO-Using-TensorFlow#inpage-nav-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom configs and meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:09.512642Z",
     "start_time": "2019-02-16T06:25:09.500674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the frozen TensorFlow object detection model.\n",
    "pb_file = \"./frozen_inference_graph.pb\"\n",
    "\n",
    "# OpenVINO subgraph replacement configuration file that describes rules to convert specific TensorFlow topologies.\n",
    "# Read more in Model optimization section.\n",
    "configuration_file = 'deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json'\n",
    "\n",
    "# The modified pipline config file used for training.\n",
    "pipeline = './ssd_mobilenet_v2_coco.config'\n",
    "\n",
    "# Devices: GPU (intel), CPU or MYRIAD\n",
    "plugin_device = 'GPU'\n",
    "\n",
    "# Specify a data type for the given device or set to `None` to let the code decide.\n",
    "# Data type 'FP16' or 'FP32' depends on what device to run the converted model.\n",
    "# FP16: GPU and MYRIAD\n",
    "# FP32 CPU and GPU\n",
    "data_type = None\n",
    "\n",
    "# Converted model take fixed size image as input,\n",
    "# we simply use same size for image width and height.\n",
    "img_height = 300\n",
    "\n",
    "# Path to a sample image to inference.\n",
    "fname = '../test/15.jpg'\n",
    "\n",
    "\n",
    "# Model Optimizer can create an event file that can be then fed to the TensorBoard tool.(Optional)\n",
    "tensorboard_logdir = None  # './models/ssd_mobilenet_v2_coco_2018_03_29/mo_tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:10.375598Z",
     "start_time": "2019-02-16T06:25:10.364627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "model_dir = os.path.dirname(os.path.realpath(pb_file))\n",
    "\n",
    "DATA_TYPE_MAP = {\n",
    "    'GPU': 'FP16',\n",
    "    'CPU': 'FP32',\n",
    "    'MYRIAD': 'FP16'\n",
    "}\n",
    "\n",
    "assert plugin_device in DATA_TYPE_MAP, 'Unsupported device: `{}`, not found in `{}`'.format(\n",
    "    plugin_device, list(DATA_TYPE_MAP.keys()))\n",
    "\n",
    "if data_type is None:\n",
    "    data_type = DATA_TYPE_MAP.get(plugin_device)\n",
    "\n",
    "# Directory to save the converted model xml and bin files.\n",
    "output_dir = os.path.join(\n",
    "    model_dir, data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`--tensorflow_use_custom_operations_config <path_to_subgraph_replacement_configuration_file.json>`\n",
    "\n",
    "- A subgraph replacement configuration file that describes rules to convert specific TensorFlow* topologies. For the models downloaded from the TensorFlow* Object Detection API zoo, you can find the configuration files in the `<INSTALL_DIR>/deployment_tools/model_optimizer/extensions/front/tf`\n",
    "\n",
    "Use:\n",
    "- `ssd_v2_support.json` - for frozen SSD topologies from the models zoo.\n",
    "- `faster_rcnn_support.json` - for frozen Faster R-CNN topologies from the models zoo.\n",
    "- `faster_rcnn_support_api_v1.7.json` - for Faster R-CNN topologies trained manually using the TensorFlow* Object Detection API version 1.7.0 or higher.\n",
    "- ...\n",
    "\n",
    "\n",
    "If the `--input_shape` command line parameter is not specified, the Model Optimizer generates an input layer with the height and width as defined in the `pipeline.config`.\n",
    "\n",
    "If the --input_shape `[1, H, W, 3]` command line parameter is specified, the Model Optimizer sets the input layer height to H and width to W and convert the model.\n",
    "\n",
    "\n",
    "NOTE: If you convert a TensorFlow* Object Detection API model to use with the Inference Engine sample applications, you must specify the `--reverse_input_channels` parameter also.  The samples load images in `BGR` channels order, while TensorFlow* models were trained with images in `RGB` order. When the `--reverse_input_channels` command line parameter is specified, the Model Optimizer performs first convolution or other channel dependent operation weights modification so the output will be like the image is passed with `RGB` channels order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T02:58:00.109363Z",
     "start_time": "2019-02-16T02:58:00.089415Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'INTEL_CVSDK_DIR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a988364c2977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Absolute path to `configuration_file`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m configuration_file = os.path.join(\n\u001b[0;32m---> 13\u001b[0;31m     os.environ[\"INTEL_CVSDK_DIR\"], configuration_file)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Prepare command line argument string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'INTEL_CVSDK_DIR'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if tensorboard_logdir:\n",
    "    tensorboard_logdir_arg = '--tensorboard_logdir {}'.format(\n",
    "        tensorboard_logdir)\n",
    "    os.makedirs(tensorboard_logdir, exist_ok=True)\n",
    "    print(tensorboard_logdir_arg)\n",
    "else:\n",
    "    tensorboard_logdir_arg = ''\n",
    "\n",
    "# Absolute path to `configuration_file`\n",
    "configuration_file = os.path.join(\n",
    "    os.environ[\"INTEL_CVSDK_DIR\"], configuration_file)\n",
    "\n",
    "# Prepare command line argument string.\n",
    "input_shape = [1, img_height, img_height, 3]\n",
    "input_shape_str = str(input_shape).replace(' ', '')\n",
    "input_shape_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate the path to `mo_tf.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T02:58:01.568219Z",
     "start_time": "2019-02-16T02:58:01.561259Z"
    }
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "is_win = 'windows' in platform.platform().lower()\n",
    "\n",
    "if is_win:\n",
    "    mo_tf_path = 'C:/Intel/computer_vision_sdk/deployment_tools/model_optimizer/mo_tf.py'\n",
    "else:\n",
    "    # mo_tf.py path in Linux\n",
    "    mo_tf_path = '~/intel/computer_vision_sdk/deployment_tools/model_optimizer/mo_tf.py'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the model optimization script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T02:58:37.786019Z",
     "start_time": "2019-02-16T02:58:04.913204Z"
    }
   },
   "outputs": [],
   "source": [
    "!python {mo_tf_path} \\\n",
    "    --input_model {pb_file} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --tensorflow_use_custom_operations_config {configuration_file} \\\n",
    "    --tensorflow_object_detection_api_pipeline_config {pipeline} \\\n",
    "    --input_shape {input_shape_str} \\\n",
    "    --data_type {data_type} \\\n",
    "    {tensorboard_logdir_arg}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference test with OpenVINO Inference Engine(IE)\n",
    "\n",
    "Check path like `C:\\Intel\\computer_vision_sdk\\python\\python3.5` or `~/intel/computer_vision_sdk/python/python3.5` exists in `PYTHONPATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:16.112243Z",
     "start_time": "2019-02-16T06:25:16.108219Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = os.path.join(model_dir, data_type)\n",
    "assert os.path.isdir(output_dir), '`{}` does not exist'.format(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:16.275074Z",
     "start_time": "2019-02-16T06:25:16.266100Z"
    }
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "is_win = 'windows' in platform.platform().lower()\n",
    "if is_win:\n",
    "    message = 'Please run `C:\\\\Intel\\\\computer_vision_sdk\\\\bin\\\\setupvars.bat` before launching jupyter notebook.'\n",
    "else:\n",
    "    message = 'Add the following line to ~/.bashrc and re-run jupyternotebook.\\nsource ~/intel/computer_vision_sdk/bin/setupvars.sh'\n",
    "\n",
    "import os\n",
    "assert 'computer_vision_sdk' in os.environ['PYTHONPATH'], message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:16.577293Z",
     "start_time": "2019-02-16T06:25:16.386649Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "try:\n",
    "    from openvino import inference_engine as ie\n",
    "    from openvino.inference_engine import IENetwork, IEPlugin\n",
    "except Exception as e:\n",
    "    exception_type = type(e).__name__\n",
    "    print(\"The following error happened while importing Python API module:\\n[ {} ] {}\".format(\n",
    "        exception_type, e))\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:27.401701Z",
     "start_time": "2019-02-16T06:25:16.579279Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Plugin initialization for specified device and load extensions library if specified.\n",
    "plugin_dir = None\n",
    "model_xml = glob.glob(os.path.join(output_dir, '*.xml'))[-1]\n",
    "model_bin = glob.glob(os.path.join(output_dir, '*.bin'))[-1]\n",
    "# Devices: GPU (intel), CPU, MYRIAD\n",
    "plugin = IEPlugin(plugin_device, plugin_dirs=plugin_dir)\n",
    "# Read IR\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "assert len(net.inputs.keys()) == 1\n",
    "assert len(net.outputs) == 1\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "# Load network to the plugin\n",
    "exec_net = plugin.load(network=net)\n",
    "del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:27.422610Z",
     "start_time": "2019-02-16T06:25:27.403677Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process_image(imagePath, img_shape):\n",
    "    \"\"\"pre process an image from image path.\n",
    "    \n",
    "    Arguments:\n",
    "        imagePath {str} -- input image file path.\n",
    "        img_shape {tuple} -- Target height and width as a tuple.\n",
    "    \n",
    "    Returns:\n",
    "        np.array -- Preprocessed image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Model input format\n",
    "    assert isinstance(img_shape, tuple) and len(img_shape) == 2\n",
    "\n",
    "    n, c, h, w = [1, 3, img_shape[0], img_shape[1]]\n",
    "    image = Image.open(imagePath)\n",
    "    processed_img = image.resize((h, w), resample=Image.BILINEAR)\n",
    "\n",
    "    processed_img = np.array(processed_img).astype(np.uint8)\n",
    "\n",
    "    # Change data layout from HWC to CHW\n",
    "    processed_img = processed_img.transpose((2, 0, 1))\n",
    "    processed_img = processed_img.reshape((n, c, h, w))\n",
    "\n",
    "    return processed_img, np.array(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:27.493548Z",
     "start_time": "2019-02-16T06:25:27.425603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run inference\n",
    "img_shape = (img_height, img_height)\n",
    "processed_img, image = pre_process_image(fname, img_shape)\n",
    "res = exec_net.infer(inputs={input_blob: processed_img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:27.505481Z",
     "start_time": "2019-02-16T06:25:27.495506Z"
    }
   },
   "outputs": [],
   "source": [
    "print(res['DetectionOutput'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Inference Engine DetectionOutput layer implementation produces one tensor with seven numbers for each actual detection:\n",
    "\n",
    "- 0: batch index\n",
    "- 1: class label\n",
    "- 2: class probability\n",
    "- 3: x_1 box coordinate (0~1 as a fraction of the image width reference to the upper left corner)\n",
    "- 4: y_1 box coordinate (0~1 as a fraction of the image height reference to the upper left corner)\n",
    "- 5: x_2 box coordinate (0~1 as a fraction of the image width reference to the upper left corner)\n",
    "- 6: y_2 box coordinate (0~1 as a fraction of the image height reference to the upper left corner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the results with a prediction probability threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:27.519448Z",
     "start_time": "2019-02-16T06:25:27.508474Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probability_threshold = 0.5\n",
    "\n",
    "preds = [pred for pred in res['DetectionOutput'][0][0] if pred[2] > probability_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:27.540388Z",
     "start_time": "2019-02-16T06:25:27.521437Z"
    }
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:49.988039Z",
     "start_time": "2019-02-16T06:25:49.773530Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.imshow(image)  # slice by z axis of the box - box[0].\n",
    "\n",
    "for pred in preds:\n",
    "    class_label = pred[1]\n",
    "    probability = pred[2]\n",
    "    print('Predict class label:{:.0f}, with probability: {:.2f}'.format(\n",
    "        class_label, probability))\n",
    "    box = pred[3:]\n",
    "    box = (box * np.array(image.shape[:2][::-1] * 2)).astype(int)\n",
    "    x_1, y_1, x_2, y_2 = box\n",
    "    rect = patches.Rectangle((x_1, y_1), x_2-x_1, y_2 -\n",
    "                             y_1, linewidth=2, edgecolor='red', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x_1, y_1, '{:.0f} - {:.2f}'.format(class_label,\n",
    "                                               probability), fontsize=12, color='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark the inference speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T06:25:28.478827Z",
     "start_time": "2019-02-16T06:25:28.075405Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "times = []\n",
    "for i in range(20):\n",
    "    start_time = time.time()\n",
    "    res = exec_net.infer(inputs={input_blob: processed_img})\n",
    "    delta = (time.time() - start_time)\n",
    "    times.append(delta)\n",
    "mean_delta = np.array(times).mean()\n",
    "fps = 1/mean_delta\n",
    "print('average(sec):{:.3f},fps:{:.2f}'.format(mean_delta,fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize frozen `.pb` file (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Visualize the frozen `.pb` file with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T11:51:55.266992Z",
     "start_time": "2019-02-12T11:51:55.250010Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "log_dir = \"./tensorboard\"\n",
    "\n",
    "pb_file = os.path.abspath(pb_file).replace('\\\\', '/')\n",
    "log_dir = os.path.abspath(log_dir).replace('\\\\', '/')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "assert os.path.isfile(pb_file)\n",
    "print('--model_dir {}'.format(pb_file))\n",
    "print('--log_dir {}'.format(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T11:50:02.433276Z",
     "start_time": "2019-02-12T11:49:50.509117Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import import_pb_to_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T11:50:02.453222Z",
     "start_time": "2019-02-12T11:50:02.436279Z"
    }
   },
   "outputs": [],
   "source": [
    "# File path to `import_pb_to_tensorboard.py`\n",
    "import_pb_to_tensorboard_py = import_pb_to_tensorboard.__file__\n",
    "import_pb_to_tensorboard_py = import_pb_to_tensorboard_py.replace('\\\\', '/')\n",
    "import_pb_to_tensorboard_py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create TensorBoard event file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T11:41:12.151624Z",
     "start_time": "2019-02-12T11:40:56.045383Z"
    }
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw(\n",
    "    'python {} --model_dir {} --log_dir {} &'\n",
    "    .format(import_pb_to_tensorboard_py, pb_file, log_dir)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-12T11:53:48.930Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-12T11:51:59.953Z"
    }
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} &'\n",
    "    .format(log_dir)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Visualize with OpenVINO `summarize_graph.py` utility.\n",
    "If you just want to know the input(s) and output(s) of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:20:41.725347Z",
     "start_time": "2019-02-13T11:20:41.719361Z"
    }
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "is_win = 'windows' in platform.platform().lower()\n",
    "\n",
    "if is_win:\n",
    "    summarize_graph_path = 'C:/Intel/computer_vision_sdk/deployment_tools/model_optimizer/mo/utils/summarize_graph.py'\n",
    "else:\n",
    "    # summarize_graph.py path in Linux\n",
    "    summarize_graph_path = '~/intel/computer_vision_sdk/deployment_tools/model_optimizer/mo/utils/summarize_graph.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:20:50.225463Z",
     "start_time": "2019-02-13T11:20:44.199402Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python {summarize_graph_path} --input_model {pb_file}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
